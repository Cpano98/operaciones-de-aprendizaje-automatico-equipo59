# ğŸ¢ PredicciÃ³n de Ausentismo Laboral con MLOps

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Version%20Control-blueviolet)](https://dvc.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

[![Tests](https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59/actions/workflows/tests.yml/badge.svg)](https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59/actions/workflows/tests.yml)
[![Code Quality](https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59/actions/workflows/code-quality.yml/badge.svg)](https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59/actions/workflows/code-quality.yml)
[![ML Pipeline](https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59/actions/workflows/ml-pipeline.yml/badge.svg)](https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59/actions/workflows/ml-pipeline.yml)

Proyecto de **Machine Learning Operations (MLOps)** desarrollado por el **Equipo 59** para predecir las horas de ausentismo laboral utilizando tÃ©cnicas de regresiÃ³n supervisada, con gestiÃ³n de datos mediante DVC y seguimiento de experimentos con MLflow.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Dataset](#-dataset)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [MetodologÃ­a](#-metodologÃ­a)
- [Fases del Proyecto](#-fases-del-proyecto)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Resultados](#-resultados)
- [Equipo](#-equipo)
- [Referencias](#-referencias)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto tiene como objetivo **predecir el nÃºmero de horas de ausencia** de empleados de una empresa de mensajerÃ­a brasileÃ±a, utilizando datos histÃ³ricos de ausentismo laboral del perÃ­odo 2007-2010.

### **PropÃ³sito de Negocio**

- ğŸ“Š **Mejorar la planificaciÃ³n operativa**: anticipar ausencias para reorganizar equipos
- ğŸ’° **Reducir costos**: minimizar impacto de ausencias inesperadas
- ğŸ¥ **DiseÃ±ar polÃ­ticas de bienestar**: identificar patrones de salud y ausentismo
- ğŸ¯ **Optimizar recursos humanos**: tomar decisiones estratÃ©gicas basadas en datos

### **Stakeholders**

- **RRHH**: diseÃ±o de programas de salud y reducciÃ³n de ausentismo
- **Supervisores**: organizaciÃ³n de equipos y cargas de trabajo
- **DirecciÃ³n**: decisiones estratÃ©gicas sobre contrataciÃ³n y retenciÃ³n
- **Empleados**: beneficiarios indirectos de polÃ­ticas personalizadas

---

## ğŸ“Š Dataset

**Fuente**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work) - Absenteeism at Work

### **CaracterÃ­sticas del Dataset**

- **PerÃ­odo**: 2007-2010
- **Instancias**: 754 registros
- **Variables**: 20 features + 1 target
- **Tipo de problema**: RegresiÃ³n supervisada
- **Variable objetivo**: `Absenteeism time in hours`

### **CategorÃ­as de Variables**

#### ğŸ”¹ Variables DemogrÃ¡ficas
- `Age`: Edad del empleado
- `Education`: Nivel educativo (1=secundaria, 2=licenciatura, 3=posgrado, 4=maestrÃ­a/doctorado)
- `Son`: NÃºmero de hijos

#### ğŸ”¹ Variables Laborales
- `Service time`: AntigÃ¼edad en la empresa
- `Work load Average/day`: Carga de trabajo promedio diaria
- `Disciplinary failure`: Registro de faltas disciplinarias (0/1)
- `Hit target`: Nivel de cumplimiento de objetivos

#### ğŸ”¹ Variables de Salud y Estilo de Vida
- `Reason for absence`: CÃ³digo ICD (International Classification of Diseases) - 29 categorÃ­as
- `Social drinker`: Consumo social de alcohol (0/1)
- `Social smoker`: Fumador social (0/1)
- `Weight`: Peso en kg
- `Height`: Altura en cm
- `Body mass index`: Ãndice de masa corporal

#### ğŸ”¹ Variables Contextuales
- `Transportation expense`: Gasto en transporte
- `Distance from Residence to Work`: Distancia al trabajo en km
- `Seasons`: EstaciÃ³n del aÃ±o (1=verano, 2=otoÃ±o, 3=invierno, 4=primavera)
- `Month of absence`: Mes de la ausencia (0-12)
- `Day of the week`: DÃ­a de la semana (2-6, lunes-viernes)
- `Pet`: NÃºmero de mascotas

---

## ğŸ“ Estructura del Repositorio

```
operaciones-de-aprendizaje-automatico-equipo59/
â”‚
â”œâ”€â”€ AbsenteeismAtWork/                      # Proyecto principal
â”‚   â”œâ”€â”€ data/                               # Datos versionados con DVC
â”‚   â”‚   â”œâ”€â”€ work_absenteeism_original.csv.dvc
â”‚   â”‚   â”œâ”€â”€ work_absenteeism_clean.csv.dvc
â”‚   â”‚   â””â”€â”€ work_absenteeism_modified.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ Phase-1/                            # Notebooks Fase 1
â”‚   â”‚   â”œâ”€â”€ data_preparation.ipynb          # Pipeline de limpieza
â”‚   â”‚   â”œâ”€â”€ eda_fe.ipynb                    # EDA y Feature Engineering
â”‚   â”‚   â””â”€â”€ work_absenteeism.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ mlruns/                             # Experimentos MLflow
â”‚   â”‚   â”œâ”€â”€ 0/                              # Experimento default
â”‚   â”‚   â””â”€â”€ models/                         # Modelos registrados
â”‚   â”‚
â”‚   â””â”€â”€ phase_1.ipynb                       # ML Canvas consolidado
â”‚
â”œâ”€â”€ scripts/                                # Scripts de apoyo
â”‚   â”œâ”€â”€ 1.intro_mlflow.ipynb               # Tutorial MLflow
â”‚   â””â”€â”€ Fase1.ipynb                        # Pipeline completo
â”‚
â”œâ”€â”€ README.md                               # Este archivo
â”œâ”€â”€ LICENSE                                 # Licencia del proyecto
â””â”€â”€ links.txt                              # Referencias Ãºtiles
```

---

## ğŸš€ InstalaciÃ³n

### **Prerequisitos**

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Git

### **1. Clonar el repositorio**

```bash
git clone https://github.com/tu-usuario/operaciones-de-aprendizaje-automatico-equipo59.git
cd operaciones-de-aprendizaje-automatico-equipo59
```

### **2. Crear entorno virtual (recomendado)**

```bash
# En Windows
python -m venv venv
venv\Scripts\activate

# En macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### **3. Instalar dependencias**

```bash
pip install -r requirements.txt
```

O instalar manualmente:

```bash
pip install mlflow
pip install pandas numpy scipy scikit-learn
pip install matplotlib seaborn
pip install ydata-profiling
pip install jupyter notebook
pip install pytest  # Para testing
```

### **4. Configurar DVC (opcional, para versionado de datos)**

```bash
pip install dvc
dvc pull  # Descarga los datasets versionados
```

---

## ğŸ”„ CI/CD Pipeline

Este proyecto incluye una suite completa de **GitHub Actions workflows** para automatizaciÃ³n:

### **Workflows Activos**

| Workflow | Trigger | DescripciÃ³n |
|----------|---------|-------------|
| **Tests** | Push/PR | Ejecuta tests unitarios en mÃºltiples plataformas y versiones de Python |
| **Code Quality** | Push/PR | Linting, formateo, type checking y anÃ¡lisis de seguridad |
| **ML Pipeline** | Cambios en datos/notebooks | Valida pipeline de preprocesamiento y notebooks |
| **Documentation** | Cambios en markdown | Valida documentaciÃ³n y enlaces |
| **DVC Sync** | Cambios en .dvc | Valida versionado de datos |
| **Model Training** | Push a main/Manual | Entrena modelo baseline y valida performance |

### **Estado de los Workflows**

Puedes ver el estado actual en la pestaÃ±a [Actions](../../actions) del repositorio.

---

## ğŸ’» Uso

### **Iniciar MLflow UI**

Para visualizar experimentos y mÃ©tricas:

```bash
cd AbsenteeismAtWork
mlflow ui
```

Abre tu navegador en: `http://127.0.0.1:5000`

### **Ejecutar notebooks**

```bash
jupyter notebook
```

Navega a los notebooks en el orden sugerido:

1. `AbsenteeismAtWork/Phase-1/data_preparation.ipynb` - Limpieza de datos
2. `AbsenteeismAtWork/Phase-1/eda_fe.ipynb` - AnÃ¡lisis exploratorio
3. `scripts/Fase1.ipynb` - Pipeline completo

### **Pipeline de Preprocesamiento**

El pipeline incluye las siguientes etapas:

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer

preprocessing_pipeline = Pipeline([
    ('drop_columns', FunctionTransformer(drop_columns)),
    ('strip_objects', FunctionTransformer(strip_object_columns)),
    ('safe_round', FunctionTransformer(safe_round_to_int_df)),
    ('fix_invalids', FunctionTransformer(fix_invalid_values)),
    ('winsorize', FunctionTransformer(winsorize_iqr)),
    ('fillna', FunctionTransformer(fillna_with_median)),
    ('final_int', FunctionTransformer(final_int_conversion))
])

df_clean = preprocessing_pipeline.fit_transform(df)
```

### **Ejecutar Tests**

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Con cobertura de cÃ³digo
pytest tests/ --cov=. --cov-report=html

# Ver reporte de cobertura
open htmlcov/index.html  # macOS
start htmlcov/index.html  # Windows
```

### **Validar Calidad de CÃ³digo**

```bash
# Linting
flake8 .

# Formateo automÃ¡tico
black .
isort .

# AnÃ¡lisis de seguridad
bandit -r .
```

---

## ğŸ”¬ MetodologÃ­a

### **Machine Learning Canvas**

El proyecto sigue la metodologÃ­a [ML Canvas](https://ignaciogavilan.com/metodologia-para-machine-learning-ii-machine-learning-canvas/) que estructura el desarrollo en 4 etapas:

1. **Objetivo** - DefiniciÃ³n del problema y stakeholders
2. **Aprender** - RecolecciÃ³n y anÃ¡lisis de datos
3. **Predecir** - SelecciÃ³n de algoritmos y mÃ©tricas
4. **Evaluar** - MonitorizaciÃ³n y mejora continua

### **Pipeline de Preprocesamiento**

#### ğŸ—‘ï¸ Variables Eliminadas

| Variable | RazÃ³n |
|----------|-------|
| `ID` | Identificador Ãºnico sin valor predictivo |
| `mixed_type_col` | Columna inconsistente sin informaciÃ³n Ãºtil |

#### ğŸ”  Transformaciones en Variables CategÃ³ricas

| Variable | TransformaciÃ³n | JustificaciÃ³n |
|----------|---------------|---------------|
| `Reason for absence` | Valores fuera de 0-28 â†’ 0 | Mantener consistencia con cÃ³digos ICD |
| `Month of absence` | Valores fuera de 0-12 â†’ 0 | Asegurar meses vÃ¡lidos |
| `Day of the week` | Valores fuera de 2-6 â†’ moda | Solo dÃ­as laborales |
| `Seasons` | Valores fuera de 1-4 â†’ moda | 4 estaciones vÃ¡lidas |
| Variables binarias | Valores != 0 o 1 â†’ moda | Mantener integridad binaria |

#### ğŸ”¢ Transformaciones en Variables NumÃ©ricas

Para **12 variables numÃ©ricas** se aplicÃ³:

1. **WinsorizaciÃ³n IQR**: Control de outliers
2. **ImputaciÃ³n con mediana**: Relleno de valores nulos
3. **Redondeo final**: ConversiÃ³n a enteros

**Resultado**: 
- âœ… 0 valores nulos
- âœ… Todas las variables en formato `int64`
- âœ… Outliers controlados

### **AnÃ¡lisis Exploratorio**

#### Correlaciones con el Target

| Variable | CorrelaciÃ³n |
|----------|-------------|
| `Disciplinary failure` | -0.263 (negativa fuerte) |
| `Reason for absence` | -0.167 |
| `Day of the week` | -0.114 |
| `Son` | +0.122 |
| `Transportation expense` | +0.121 |
| `Social drinker` | +0.117 |

**Insight**: Las faltas disciplinarias son el predictor mÃ¡s fuerte (correlaciÃ³n negativa).

---

## ğŸ“ˆ Fases del Proyecto

### âœ… **Fase 1: PreparaciÃ³n y AnÃ¡lisis** (Completada)

- [x] DefiniciÃ³n del problema (ML Canvas)
- [x] Carga y exploraciÃ³n inicial del dataset
- [x] Pipeline de limpieza de datos
- [x] AnÃ¡lisis exploratorio de datos (EDA)
- [x] Feature Engineering bÃ¡sico
- [x] Versionado de datos con DVC
- [x] Setup de MLflow

### ğŸ”„ **Fase 2: Modelado** (En progreso)

- [ ] Entrenamiento de modelos baseline
- [ ] ExperimentaciÃ³n con mÃºltiples algoritmos:
  - RegresiÃ³n Lineal
  - Random Forest Regressor
  - Gradient Boosting (XGBoost, LightGBM)
  - CatBoost
- [ ] OptimizaciÃ³n de hiperparÃ¡metros
- [ ] ValidaciÃ³n cruzada
- [ ] Registro de experimentos en MLflow

### â³ **Fase 3: EvaluaciÃ³n y SelecciÃ³n**

- [ ] ComparaciÃ³n de mÃ©tricas (MAE, RMSE, RÂ²)
- [ ] AnÃ¡lisis de importancia de features
- [ ] SelecciÃ³n del mejor modelo
- [ ] EvaluaciÃ³n en conjunto de prueba
- [ ] AnÃ¡lisis de residuos

### â³ **Fase 4: Despliegue y Monitoreo**

- [ ] Empaquetado del modelo final
- [ ] Desarrollo de API (FastAPI/Flask)
- [ ] ContainerizaciÃ³n con Docker
- [ ] Monitoreo de drift
- [ ] DocumentaciÃ³n de producciÃ³n

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### **Lenguajes y LibrerÃ­as**

- **Python 3.8+**: Lenguaje principal
- **Pandas**: ManipulaciÃ³n de datos
- **NumPy**: CÃ¡lculos numÃ©ricos
- **Scikit-learn**: Modelado y preprocesamiento
- **Matplotlib & Seaborn**: VisualizaciÃ³n

### **MLOps Tools**

- **MLflow**: Tracking de experimentos y registro de modelos
- **DVC**: Control de versiones de datos
- **Jupyter Notebook**: Desarrollo interactivo

### **Herramientas de AnÃ¡lisis**

- **ydata-profiling**: GeneraciÃ³n de reportes automÃ¡ticos
- **SciPy**: AnÃ¡lisis estadÃ­stico

---

## ğŸ“Š Resultados

### **Versionado de Datos**

| VersiÃ³n | Archivo | DescripciÃ³n | TamaÃ±o | Fecha |
|---------|---------|-------------|--------|-------|
| v1 | `work_absenteeism_original.csv` | Dataset original sin procesar | 45 KB | 2025-10-09 |
| v2 | `work_absenteeism_clean.csv` | Dataset limpio y procesado | 41 KB | 2025-10-10 |

### **Feature Engineering**

- **NormalizaciÃ³n**: StandardScaler aplicado a 8 variables continuas
- **Encoding**: One-hot encoding de variables categÃ³ricas
- **PCA**: 2 componentes principales explican **51.88%** de la varianza

### **MÃ©tricas Objetivo**

Para la fase de modelado se utilizarÃ¡n:

- **MAE** (Mean Absolute Error): Error promedio en horas
- **RMSE** (Root Mean Squared Error): Penaliza errores grandes
- **RÂ²** (Coeficiente de DeterminaciÃ³n): ProporciÃ³n de varianza explicada
- **ValidaciÃ³n Cruzada**: K-Fold (k=5)

---

## ğŸ‘¥ Equipo

**Equipo 59** - Master en Inteligencia Artificial

- Jorge - Data Preprocessing & Feature Engineering
- Miguel - EDA & Data Analysis
- [AÃ±adir mÃ¡s miembros segÃºn corresponda]

**InstituciÃ³n**: TecnolÃ³gico de Monterrey  
**Curso**: Operaciones de Aprendizaje AutomÃ¡tico

---

## ğŸ“š Referencias

### **Dataset**
- [UCI ML Repository - Absenteeism at Work Dataset](https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work)

### **MetodologÃ­a**
- [Machine Learning Canvas - Ignacio GavilÃ¡n](https://ignaciogavilan.com/metodologia-para-machine-learning-ii-machine-learning-canvas/)

### **Herramientas**
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [DVC Documentation](https://dvc.org/doc)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)

### **Papers y ArtÃ­culos**
- International Classification of Diseases (ICD) - WHO

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

<div align="center">

Desarrollado con â¤ï¸ por el Equipo 59

</div>
